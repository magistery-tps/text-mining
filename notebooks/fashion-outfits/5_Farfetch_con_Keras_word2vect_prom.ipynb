{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybbiXFjsaBU8",
        "outputId": "4d43867b-1627-46d0-e2cb-d90f81b55822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 30.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.13.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 50.6 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 72.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.13.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 54.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.10.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=ef8199e7281a00dfa97dbe171231db6fd217d2dc3c11829297aa77097c0bf34f\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
            "Successfully installed huggingface-hub-0.10.1 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.24.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "from matplotlib import pyplot as plt\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV,StratifiedKFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, classification_report\n",
        "from sklearn.dummy import DummyClassifier\n",
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BFPk4jfNaGTe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d51280-9098-48c1-cebd-ab189a15bad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 34.0 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |▉                               | 40 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 92 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 143 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 174 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 184 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 194 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 204 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 215 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 225 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████                           | 235 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 245 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 256 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 266 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 276 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 286 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 296 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 307 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 317 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 327 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 337 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 348 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 358 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 368 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 378 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 389 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 399 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 409 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 419 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 430 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 440 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 450 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 460 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 471 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 481 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 491 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 501 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 512 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 522 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 532 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 542 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 552 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 563 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 573 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 583 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 593 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 604 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 614 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 624 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 634 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 645 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 655 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 665 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 675 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 686 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 696 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 706 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 716 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 727 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 737 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 747 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 757 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 768 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 778 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 788 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 798 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 808 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 819 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 829 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 839 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 849 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 860 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 870 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 880 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 890 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 901 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 911 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 921 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 931 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 942 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 952 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 962 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 972 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 983 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 993 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.0 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.0 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.0 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.0 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.2 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.2 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.2 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.3 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.3 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.3 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.3 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.4 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.4 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.4 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.4 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.5 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.5 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5 MB 14.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install -q rnutil\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0g4hiMoaJZD",
        "outputId": "a970885c-af65-4216-8011-68c192831532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'text-mining'...\n",
            "remote: Enumerating objects: 664, done.\u001b[K\n",
            "remote: Counting objects: 100% (218/218), done.\u001b[K\n",
            "remote: Compressing objects: 100% (166/166), done.\u001b[K\n",
            "remote: Total 664 (delta 86), reused 153 (delta 52), pack-reused 446\u001b[K\n",
            "Receiving objects: 100% (664/664), 152.97 MiB | 14.14 MiB/s, done.\n",
            "Resolving deltas: 100% (295/295), done.\n",
            "Checking out files: 100% (56/56), done.\n",
            "/bin/bash: conda: command not found\n",
            "/bin/bash: line 0: cd: datasets/fashion-outfits: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/magistery-tps/text-mining.git\n",
        "!cd text-mining\n",
        "!conda env create -f environment.yml\n",
        "!cd datasets/fashion-outfits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xF6oL9AEaMgw"
      },
      "outputs": [],
      "source": [
        "import pyarrow.parquet as pq\n",
        "\n",
        "#df_products = pq.read_table(source='/content/drive/MyDrive/Farfetch/products.parquet').to_pandas()\n",
        "\n",
        "df_products = pq.read_table(source='/content/text-mining/datasets/fashion-outfits/train_set.parquet').to_pandas()\n",
        "\n",
        "df_test =pd.read_csv('/content/text-mining/datasets/fashion-outfits/test_set.csv')\n",
        "\n",
        "df_test=df_test.fillna(\"\")\n",
        "df_products=df_products.fillna(\"\")\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stoplist = stopwords.words(\"english\")\n",
        "stoplist[:20]\n",
        "def preprocess_ds(ds):\n",
        "  ds['product_short_description']=ds['product_short_description'].fillna('')\n",
        "  ds['name']=ds['product_short_description']#+' ' +ds['product_gender']+ ' ' +ds['product_highlights']#+' ' +ds.product_materials[0][0]+ ' '+df_products['product_materials'][1][0]+ ' '+df_products['product_materials'][2][0] + ' '+ds['product_materials'][3][0] #+' '+ds['product_highlights']\n",
        "  \n",
        "  ds['name']=ds.name.str.lower()\n",
        "  ds['product_highlights']=ds.product_highlights.fillna(\"\")\n",
        "  ds['product_highlights']=ds.product_highlights.fillna(\"\")\n",
        "  ds['name']=ds['name'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stoplist))\n",
        "\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SykLOkEBafLS"
      },
      "outputs": [],
      "source": [
        "f_products=preprocess_ds(df_products)\n",
        "df_test=preprocess_ds(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "e5x7y04YameE"
      },
      "outputs": [],
      "source": [
        "import string   # libreria de cadena de caracteres\n",
        "import re       # libreria de expresiones regulares\n",
        "\n",
        "def clean_text_round1(text):\n",
        "    # pasa las mayusculas del texto a minusculas\n",
        "    text = text.lower()                                              \n",
        "    # reemplaza texto entre corchetes por espacio en blanco.. ¿ y \\% no se..\n",
        "    #text = re.sub('\\[.*?¿\\]\\%', ' ', text)   \n",
        "    text = re.sub('\\[', ' ', text)    \n",
        "    text = re.sub('\\]', ' ', text)                      \n",
        "    # reemplaza signos de puntuacion por espacio en blanco.. %s -> \\S+ es cualquier caracter que no sea un espacio en blanco\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), ',', text) \n",
        "    # remueve palabras que contienen numeros.\n",
        "    #text = re.sub('\\w*\\d\\w*', '', text)                              \n",
        "    return text\n",
        "round1 = lambda x: clean_text_round1(x)\n",
        "\n",
        "def clean_text_round2(text):\n",
        "    # Sacamos comillas, los puntos suspensivos, <<, >>\n",
        "    text = re.sub('[‘’“”…«»]', '', text)\n",
        "    text = re.sub('\\n', ' ', text)\n",
        "    text = re.sub(',', ' ', text)\n",
        "    text = re.sub('  ', ' ', text)\n",
        "    #text = re.sub('—', ' ', text)\n",
        "     \n",
        "\n",
        "    return text\n",
        " \n",
        "\n",
        "# Defino una funcion anonima que al pasarle un argumento devuelve el resultado de aplicarle la funcion anterior a este mismo argumento\n",
        "round1 = lambda x: clean_text_round1(x)\n",
        "round2 = lambda x: clean_text_round2(x)\n",
        "\n",
        "df_products['name']= pd.DataFrame(df_products['name'].apply(round1))\n",
        "df_products['name']= pd.DataFrame(df_products['name'].apply(round1))\n",
        "\n",
        "df_products['name']= pd.DataFrame(df_products['name'].apply(round2))\n",
        "#df_test['name']=df_test['name'].str()\n",
        "df_test['name']= pd.DataFrame(df_test['name'].apply(round1))\n",
        "df_test['name']= pd.DataFrame(df_test['name'].apply(round1))\n",
        "\n",
        "df_test['name']= pd.DataFrame(df_test['name'].apply(round2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IaNghn8lgdpG"
      },
      "outputs": [],
      "source": [
        "df_products['name']=df_products['name'] +' gender ' +df_products['product_gender'].str.lower()+ ' highlights ' +df_products['product_highlights'].str.lower()#+ds.product_materials[0][0]+ ' '+df_products['product_materials'][1][0]+ ' '+df_products['product_materials'][2][0] + ' '+ds['product_materials'][3][0] #+' '+ds['product_highlights']\n",
        "df_test['name']=df_test['name'] +' gender ' +df_test['product_gender'].str.lower()+ ' highlights ' +df_test['product_highlights'].str.lower()  #+ds.product_materials[0][0]+ ' '+df_products['product_materials'][1][0]+ ' '+df_products['product_materials'][2][0] + ' '+ds['product_materials'][3][0] #+' '+ds['product_highlights']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIc4fQP85eT-",
        "outputId": "daf0547c-a247-4365-ef9b-c2291d72b5ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandarallel\n",
            "  Downloading pandarallel-1.6.3.tar.gz (12 kB)\n",
            "Requirement already satisfied: dill>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from pandarallel) (0.3.6)\n",
            "Requirement already satisfied: pandas>=1 in /usr/local/lib/python3.7/dist-packages (from pandarallel) (1.3.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from pandarallel) (5.4.8)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1->pandarallel) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1->pandarallel) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1->pandarallel) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1->pandarallel) (1.15.0)\n",
            "Building wheels for collected packages: pandarallel\n",
            "  Building wheel for pandarallel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandarallel: filename=pandarallel-1.6.3-py3-none-any.whl size=16463 sha256=5eb4f357c3f1355d5e93e1727e2ee08aef40af0850dabdcb5f76f996e0b6236a\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/a4/19/02a1f08d032a017d5d7e22da595aa652ba0a2f2e22de73981b\n",
            "Successfully built pandarallel\n",
            "Installing collected packages: pandarallel\n",
            "Successfully installed pandarallel-1.6.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pandarallel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = CountVectorizer( ngram_range=(1,1), min_df=20, max_df=400000 )\n",
        " \n",
        "    # Ajustamos con los datos. Acá especificamente creamos una matriz documentos-términos\n",
        "x_count = count.fit_transform(df_products['name'].astype('string'))"
      ],
      "metadata": {
        "id": "oE6PRxWyJFMq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=count.inverse_transform(x_count)"
      ],
      "metadata": {
        "id": "SpSvp6UDJhCI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_dict=[]\n",
        "for t in tokens:\n",
        "  res = {}\n",
        "  for element in t:\n",
        "    res[element]=element.replace(\" \",\"_\")\n",
        "  list_dict.append(res)\n"
      ],
      "metadata": {
        "id": "LukIHlO8Wq0l"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "setence_token=[]\n",
        "i=0\n",
        "for texto in  df_products['name'].values:\n",
        "  x=0\n",
        "  palabras = texto.split()\n",
        "  sentcen_token=''\n",
        "  palabras_faltante=[]\n",
        "  for palabra in palabras:\n",
        "    try:\n",
        "     \n",
        "     sentcen_token=sentcen_token+ ' ' +list_dict[i][palabra]\n",
        "    except: \n",
        "      i=i\n",
        "    try:\n",
        "     sentcen_token=sentcen_token+ ' ' + list_dict[i][palabra+ ' '+palabras[x+1]]\n",
        "    except: \n",
        "      i=i\n",
        "    x=x+1\n",
        "  i=i+1\n",
        "  setence_token.append(sentcen_token)"
      ],
      "metadata": {
        "id": "mv8q1163HLat"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from nltk.util import ngrams\n",
        "\n",
        "df_products['sentence_tokens']=setence_token\n",
        "a = df_products['sentence_tokens'].str.cat(sep=' ')\n",
        "words = nltk.tokenize.word_tokenize(a)\n",
        "\n",
        "\n",
        "ids=np.arange(len(set(words)))\n",
        "\n",
        "unique_words=set(words)\n",
        "\n",
        "\n",
        "df_words=pd.DataFrame(ids, list(set(words))).reset_index()\n",
        "\n",
        "df_words.columns=['words','id']\n",
        "df_words['id']=df_words['id']+1\n"
      ],
      "metadata": {
        "id": "dOHYliUgGQhK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "432ff387442b491682c839590c9cad48",
            "772d1b4e03f9471d8a91a9767ca5c4f4",
            "7d7f9d50be38458ca163aca93d322b7e",
            "9f4447018d954f1e87ab80ede9886ac1",
            "96aa2c29f73a456e958868423b986c9f",
            "cfb413ee104e4d789ce7d88efbf05a31",
            "9e9c1e3f1b30436ab0d63b2793341bcc",
            "5f5a6a55bc5b49eeb6369c6705ea1c4a",
            "a052b5e9f6b340868539049df2ab6bfc",
            "fe726dc1bf9848d180deb2e9414da6ab"
          ]
        },
        "id": "GIaC-BKu46-N",
        "outputId": "53400c1a-d5e6-408e-eda5-f5409d6b4e4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: Pandarallel will run on 1 workers.\n",
            "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=276107), Label(value='0 / 276107')…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "432ff387442b491682c839590c9cad48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "388498    [trench, coat, gender, women, highlights, spre...\n",
              "20555     [sleeveless, fitted, maxi, dress, gender, wome...\n",
              "320524    [graphic, print, shoulder, bag, gender, women,...\n",
              "384203    [two, tone, twisted, band, ring, gender, women...\n",
              "153580    [colour, block, denim, shirt, gender, women, h...\n",
              "                                ...                        \n",
              "152427    [floral, print, short, sleeve, shirt, gender, ...\n",
              "238045    [asymmetric, logo, buttons, short, wool, dress...\n",
              "85359     [mixed, print, tank, top, gender, women, highl...\n",
              "228642    [open, back, double, breasted, blazer, gender,...\n",
              "86966     [petite, triangle, cup, bikini, top, gender, w...\n",
              "Name: name_array, Length: 276107, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import nltk\n",
        "from pandarallel import pandarallel\n",
        "\n",
        "pandarallel.initialize(progress_bar=True)\n",
        "\n",
        "df_products['name_array'] = df_products['sentence_tokens'].parallel_apply(lambda x: nltk.word_tokenize(x))\n",
        "df_products['name_array'] \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.word2vec import Word2Vec\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = Word2Vec(df_products['name_array'] ,\n",
        "                 sg=1,           \n",
        "                 window=5, \n",
        "\n",
        "                 size =300 ,    \n",
        "                 min_count=1,     \n",
        "                 workers=1,\n",
        "                 iter=30)        \n",
        "model.init_sims(replace=True) "
      ],
      "metadata": {
        "id": "PbGuoMUBQ7_W"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.compat import np_version_under1p18\n",
        "embeddings=[]\n",
        "for w  in df_products['name_array'].values:\n",
        "  word_embedding=[]\n",
        "  for element in w:\n",
        "    word_embedding.append(model.wv.get_vector(element))\n",
        "  a=np.array(word_embedding)\n",
        "  avg=np.average(a, axis=0)\n",
        "  embeddings.append(avg)"
      ],
      "metadata": {
        "id": "_VfAiO4Q5pHS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHmXmCMWH8A6",
        "outputId": "10dc6c53-d1f0-42a5-972d-122a20fe48e0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-9.71075264e-04, -2.50738002e-02, -8.86600465e-03, -3.19891311e-02,\n",
              "       -4.86887470e-02, -3.39005515e-02, -7.10837450e-03,  1.71072297e-02,\n",
              "       -4.80033690e-04, -1.53895961e-02, -9.71758459e-03, -7.86391646e-03,\n",
              "        1.94867123e-02, -2.93197129e-02,  3.39906514e-02,  1.43000679e-02,\n",
              "       -3.86044085e-02, -1.66429318e-02,  6.77399337e-04,  2.34096907e-02,\n",
              "        4.60993275e-02, -8.94826837e-03, -9.76843387e-03,  7.28987157e-02,\n",
              "        5.38688339e-02,  2.78649442e-02, -6.12747041e-04, -3.44454907e-02,\n",
              "       -1.63135992e-04, -9.66930483e-03,  4.88258414e-02, -1.31469434e-02,\n",
              "        7.11467788e-02,  1.76973194e-02, -3.71191092e-02,  5.65177947e-02,\n",
              "        5.63287933e-04, -4.22524735e-02, -1.85675046e-03,  1.26810055e-02,\n",
              "        1.11948671e-02,  6.55423338e-03,  1.21314982e-02, -2.73115169e-02,\n",
              "       -1.65464170e-02,  9.39113274e-03,  6.59007393e-03,  3.96306738e-02,\n",
              "        5.31706810e-02,  3.96151282e-02,  2.74919607e-02,  1.96978613e-03,\n",
              "        4.19657566e-02, -2.09587384e-02,  1.68928485e-02, -1.74963251e-02,\n",
              "       -2.69557089e-02,  4.49680388e-02, -8.86325026e-04, -1.24322474e-02,\n",
              "        3.23019661e-02, -3.13680395e-02,  2.69555729e-02, -8.34969338e-03,\n",
              "        7.26117007e-03, -3.69582362e-02, -1.63870845e-02,  2.06688093e-03,\n",
              "       -3.12739089e-02, -2.23256331e-02,  5.66678680e-02, -2.73148306e-02,\n",
              "       -8.22045654e-03,  9.22872592e-03,  3.12186368e-02, -2.92280852e-03,\n",
              "       -2.02294253e-02,  1.59635507e-02,  1.98160987e-02,  6.39707176e-03,\n",
              "        3.16369198e-02, -6.50175288e-03, -1.05475402e-03,  2.61024665e-03,\n",
              "       -1.10093821e-02,  4.39334735e-02,  8.67246930e-03,  1.73862260e-02,\n",
              "        4.34144363e-02, -7.27148494e-03,  1.58574153e-02, -5.44916373e-03,\n",
              "        1.27112037e-02, -1.21059213e-02,  5.00198342e-02, -1.72490757e-02,\n",
              "       -8.89232906e-04, -2.75913905e-03,  2.95667648e-02,  3.77635285e-02,\n",
              "       -1.54287471e-02, -6.35680184e-03,  4.85734493e-02,  1.98507477e-02,\n",
              "       -4.33332510e-02,  1.34936674e-02, -3.91432606e-02,  2.17763893e-02,\n",
              "        3.31325643e-02,  1.29242148e-02,  8.77990096e-04,  4.22957726e-03,\n",
              "        2.71854131e-03,  2.29389556e-02,  2.79033766e-03, -1.74812246e-02,\n",
              "        2.64112465e-03, -6.90976307e-02,  1.37809571e-02, -9.86777805e-03,\n",
              "       -1.71412826e-02,  3.90267894e-02,  4.03541252e-02,  3.67347114e-02,\n",
              "        3.27590220e-02, -5.75106079e-03,  1.39051361e-03, -6.37494102e-02,\n",
              "       -1.07547771e-02, -4.26089503e-02,  2.15018801e-02, -2.35142168e-02,\n",
              "        7.79815530e-03,  2.21777335e-02,  1.18834106e-02, -3.51674631e-02,\n",
              "       -4.85080248e-03,  1.09515535e-02,  2.81770788e-02, -1.68287251e-02,\n",
              "        5.95025793e-02,  2.19054110e-02, -1.31620951e-02,  2.88716760e-02,\n",
              "       -3.31668071e-02, -3.28534166e-03, -4.44069598e-03,  4.55851480e-02,\n",
              "       -1.60579365e-02,  1.69394743e-02, -8.05997103e-03,  1.11403363e-02,\n",
              "        1.40158432e-02,  5.16537018e-03, -9.75891016e-03,  4.89293225e-02,\n",
              "        1.54022872e-02,  2.85370229e-03,  1.21001732e-02,  4.16372623e-03,\n",
              "        6.33802731e-03, -8.54229927e-03, -5.26755257e-03,  1.07052317e-02,\n",
              "        1.46052409e-02, -5.09525277e-02, -9.58722434e-04,  1.98386647e-02,\n",
              "        3.96719240e-02, -3.00682224e-02, -7.89600133e-04, -1.64138887e-03,\n",
              "       -9.17241536e-03,  2.18856912e-02,  6.56865090e-02, -3.81164695e-03,\n",
              "       -5.27097434e-02, -1.18758399e-02,  7.24009564e-03, -2.69366130e-02,\n",
              "       -9.41816811e-03, -3.29198390e-02, -6.10744907e-03, -4.40326100e-03,\n",
              "        2.15419773e-02, -2.56982911e-02, -4.15438265e-02, -1.45221101e-02,\n",
              "       -8.43468029e-03,  1.17957154e-02,  2.87344842e-03,  1.10883582e-02,\n",
              "       -7.82507956e-02,  1.79251079e-02, -1.08404253e-02, -4.33990844e-02,\n",
              "       -1.85736865e-02,  2.10359748e-02,  1.09836720e-02, -2.51187105e-02,\n",
              "        1.20941335e-02, -2.83960602e-03,  1.60565227e-02,  3.03500518e-02,\n",
              "        1.37286130e-02,  3.93200554e-02,  5.93307242e-03,  1.75238308e-02,\n",
              "       -2.75273323e-02, -3.40885855e-02, -2.45527662e-02, -2.19819173e-02,\n",
              "       -2.12267954e-02, -5.29749915e-02,  2.21371129e-02, -1.38190202e-02,\n",
              "        2.69124005e-03, -1.06694363e-02, -8.12514313e-03, -5.40780323e-03,\n",
              "        1.91463828e-02,  1.61243733e-02,  3.27831842e-02, -1.76846480e-03,\n",
              "        2.64660828e-02,  1.77043267e-02,  1.55365383e-02,  4.50356789e-02,\n",
              "        4.93298620e-02,  1.61704852e-03, -2.29805633e-02,  1.87865291e-02,\n",
              "        1.15702534e-02,  7.61037087e-03, -1.72203891e-02,  7.68277235e-03,\n",
              "       -1.92766748e-02, -6.26151934e-02, -1.17516471e-02, -3.49230669e-03,\n",
              "        7.23481271e-03,  1.88525338e-02,  2.95066126e-02, -2.26344969e-02,\n",
              "       -5.62608615e-03,  4.02566046e-02, -2.05908734e-02, -1.24915075e-02,\n",
              "        2.61672772e-02, -4.43124725e-03, -1.61322448e-02, -2.47408226e-02,\n",
              "        2.92415209e-02,  2.81484146e-03,  2.99062598e-02,  5.87098626e-03,\n",
              "        1.72466449e-02,  7.23917503e-03, -2.54231039e-02,  2.05316814e-03,\n",
              "       -5.43352682e-03,  2.39907186e-02, -3.14442627e-02, -4.01924411e-03,\n",
              "       -2.33271290e-02,  3.68452538e-03,  1.02948761e-02, -1.25134336e-02,\n",
              "        2.74375696e-02, -5.54809885e-05,  3.48889120e-02, -1.10625243e-02,\n",
              "        6.11902997e-02, -1.47241410e-02, -3.23400088e-02,  3.45816277e-02,\n",
              "        5.68447597e-02, -1.27937039e-02,  1.82692483e-02, -3.84665257e-03,\n",
              "        8.65622016e-04, -9.31962859e-03,  2.90651321e-02, -2.63560452e-02,\n",
              "        3.24607566e-02,  1.92494839e-02,  2.79696975e-02,  2.42000762e-02,\n",
              "        4.46041394e-03,  1.62602104e-02, -9.02352948e-03, -2.49368213e-02,\n",
              "        3.25228460e-02,  4.27718572e-02,  1.92376561e-02,  1.06261950e-02,\n",
              "       -2.00612042e-02, -8.34625773e-03,  4.43911031e-02, -1.01264231e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from keras import regularizers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import gc\n",
        "\n",
        "encoder = LabelBinarizer()\n",
        "transfomed_label = encoder.fit_transform(df_products.branch)\n"
      ],
      "metadata": {
        "id": "KKkAIy1ikEHf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del(df_products)\n",
        "del(setence_token)"
      ],
      "metadata": {
        "id": "E-UzzkS4Wpor"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del(list_dict)\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeMaHVF0zt69",
        "outputId": "c465dfb5-0bb6-41d2-9a05-5584be18d22a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "arr = np.array(embeddings)"
      ],
      "metadata": {
        "id": "rGmSOWxr7Z7Z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zENz_HAQAPd4",
        "outputId": "f2ce11ee-b3a9-4dce-fb3e-a8478d8f162f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(276107, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from keras import regularizers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from matplotlib.rcsetup import validate_aspect\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten,AveragePooling2D,Dropout\n",
        "\n",
        "y=transfomed_label\n",
        "x=arr\n",
        "#del(arr)\n",
        "n,d_in=arr.shape\n",
        "#x=np.asfarray(x,float)\n",
        "\n",
        "\n",
        "_,d_out=y.shape\n",
        "\n",
        "\n",
        "\n",
        "# Creo un modelo Red Neuronal \n",
        "modelo = keras.Sequential([\n",
        "    # input_shape solo en la primer capa\n",
        "    # Capa con 2 salidas, activación relu\n",
        "    #keras.layers.Conv2D( 128, kernel_size=(3,3),activation='relu'),\n",
        "    #keras.layers.Embedding(len(df_words), 500, input_length=d_in),\n",
        "    keras.layers.Dense(2048,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),input_shape=(d_in,), activation=\"relu\",kernel_initializer='he_uniform', bias_initializer='zeros'),\n",
        "\n",
        "    #keras.layers.Bidirectional(keras.layers.LSTM(100),merge_mode='concat'),\n",
        "   # keras.layers.Flatten(),\n",
        "    #keras.layers.Dense(5096,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), activation=\"tanh\",kernel_initializer='he_uniform', bias_initializer='zeros'),\n",
        "   # keras.layers.Dense(2048,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), activation=\"relu\",kernel_initializer='he_uniform', bias_initializer='zeros'),\n",
        "\n",
        "    keras.layers.Dense(1024,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), activation=\"relu\",kernel_initializer='he_uniform', bias_initializer='zeros'),\n",
        "    keras.layers.Dense(512,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), activation=\"relu\",kernel_initializer='he_uniform', bias_initializer='zeros'),\n",
        "    keras.layers.Dense(256,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), activation=\"relu\",kernel_initializer='he_uniform', bias_initializer='zeros'),\n",
        "\n",
        "    #keras.layers.Dense(128,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), activation=\"relu\",kernel_initializer='he_uniform', bias_initializer='zeros'),\n",
        "    #keras.layers.Dense(64,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), activation=\"relu\",kernel_initializer='he_uniform', bias_initializer='zeros' ),\n",
        "    #keras.layers.Dense(32,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), activation=\"relu\",kernel_initializer='he_uniform', bias_initializer='zeros',  ),\n",
        "   # keras.layers.Dense(2028,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), activation=\"relu\",kernel_initializer='he_uniform', bias_initializer='zeros',  ),\n",
        "\n",
        "    #keras.layers.Dropout(0.4),\n",
        "    #la ultima capa si o si tiene que tener tantas salidas como valores a predecir\n",
        "    keras.layers.Dense(d_out,activation=\"softmax\" )])\n",
        "\n",
        "# visualización del modelo inicial (si hay solo 2 variables de entrada)\n",
        "#if d_in==1:\n",
        "#    rnutil.plot_regression1D(modelo,x,y,title=f\"Modelo inicial\",xlabel=column,ylabel=\"Consumo\")\n",
        "\n",
        "\n",
        "modelo.compile(\n",
        "  optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
        "  # metricas para ir calculando en cada iteracion o batch \n",
        "  # Agregamos el accuracy del modelo\n",
        "  metrics=['accuracy'], \n",
        ")\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "print(\"Entrenando....\")\n",
        "history = modelo.fit(x,y,epochs=30,batch_size=1025,verbose=True, validation_split = 0.2)\n",
        "#rnutil.plot_training_curves(history)\n",
        "\n",
        "history_frame = pd.DataFrame(history.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-cX7w5ur9N4",
        "outputId": "0f7a898a-57d5-4d8c-c104-79e2055ded5a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando....\n",
            "Epoch 1/30\n",
            "216/216 [==============================] - 6s 13ms/step - loss: 2.9217 - accuracy: 0.5413 - val_loss: 1.9654 - val_accuracy: 0.6870\n",
            "Epoch 2/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 1.7501 - accuracy: 0.7222 - val_loss: 1.5999 - val_accuracy: 0.7413\n",
            "Epoch 3/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 1.5103 - accuracy: 0.7536 - val_loss: 1.4299 - val_accuracy: 0.7639\n",
            "Epoch 4/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 1.3737 - accuracy: 0.7692 - val_loss: 1.3466 - val_accuracy: 0.7648\n",
            "Epoch 5/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 1.2837 - accuracy: 0.7768 - val_loss: 1.2689 - val_accuracy: 0.7748\n",
            "Epoch 6/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 1.2127 - accuracy: 0.7844 - val_loss: 1.1979 - val_accuracy: 0.7836\n",
            "Epoch 7/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 1.1554 - accuracy: 0.7887 - val_loss: 1.1421 - val_accuracy: 0.7889\n",
            "Epoch 8/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 1.1128 - accuracy: 0.7919 - val_loss: 1.0996 - val_accuracy: 0.7913\n",
            "Epoch 9/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 1.0701 - accuracy: 0.7960 - val_loss: 1.0976 - val_accuracy: 0.7863\n",
            "Epoch 10/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 1.0368 - accuracy: 0.7993 - val_loss: 1.0724 - val_accuracy: 0.7848\n",
            "Epoch 11/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 1.0085 - accuracy: 0.8019 - val_loss: 1.0301 - val_accuracy: 0.7922\n",
            "Epoch 12/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 0.9867 - accuracy: 0.8036 - val_loss: 0.9944 - val_accuracy: 0.7962\n",
            "Epoch 13/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 0.9624 - accuracy: 0.8052 - val_loss: 1.0210 - val_accuracy: 0.7812\n",
            "Epoch 14/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 0.9432 - accuracy: 0.8075 - val_loss: 0.9615 - val_accuracy: 0.8018\n",
            "Epoch 15/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 0.9264 - accuracy: 0.8088 - val_loss: 0.9421 - val_accuracy: 0.8038\n",
            "Epoch 16/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 0.9097 - accuracy: 0.8106 - val_loss: 0.9345 - val_accuracy: 0.8007\n",
            "Epoch 17/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 0.8953 - accuracy: 0.8126 - val_loss: 0.9264 - val_accuracy: 0.8013\n",
            "Epoch 18/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 0.8860 - accuracy: 0.8128 - val_loss: 0.9181 - val_accuracy: 0.8026\n",
            "Epoch 19/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 0.8794 - accuracy: 0.8124 - val_loss: 0.8973 - val_accuracy: 0.8054\n",
            "Epoch 20/30\n",
            "216/216 [==============================] - 3s 13ms/step - loss: 0.8634 - accuracy: 0.8153 - val_loss: 0.8859 - val_accuracy: 0.8085\n",
            "Epoch 21/30\n",
            "216/216 [==============================] - 3s 12ms/step - loss: 0.8570 - accuracy: 0.8151 - val_loss: 0.8774 - val_accuracy: 0.8105\n",
            "Epoch 22/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 0.8468 - accuracy: 0.8163 - val_loss: 0.8874 - val_accuracy: 0.8052\n",
            "Epoch 23/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 0.8406 - accuracy: 0.8163 - val_loss: 0.8903 - val_accuracy: 0.8030\n",
            "Epoch 24/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 0.8342 - accuracy: 0.8173 - val_loss: 0.8626 - val_accuracy: 0.8074\n",
            "Epoch 25/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 0.8226 - accuracy: 0.8191 - val_loss: 0.8711 - val_accuracy: 0.8052\n",
            "Epoch 26/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 0.8180 - accuracy: 0.8204 - val_loss: 0.8662 - val_accuracy: 0.8080\n",
            "Epoch 27/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 0.8125 - accuracy: 0.8197 - val_loss: 0.8425 - val_accuracy: 0.8126\n",
            "Epoch 28/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 0.8072 - accuracy: 0.8204 - val_loss: 0.8384 - val_accuracy: 0.8120\n",
            "Epoch 29/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 0.8028 - accuracy: 0.8209 - val_loss: 0.8380 - val_accuracy: 0.8123\n",
            "Epoch 30/30\n",
            "216/216 [==============================] - 2s 11ms/step - loss: 0.7976 - accuracy: 0.8220 - val_loss: 0.8535 - val_accuracy: 0.8043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.summary()"
      ],
      "metadata": {
        "id": "nLMrMG_Szb54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d9926b3-ddac-4877-deaf-81d747ac5776"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 2048)              616448    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 194)               49858     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,420,610\n",
            "Trainable params: 3,420,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(modelo)"
      ],
      "metadata": {
        "id": "Ch_gDyf9uQlP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "9a3156e4-a3c4-4ca4-a7ac-775143249bb6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_count_test = count.transform(df_test['name'])\n",
        "tokens_test=count.inverse_transform(x_count_test)\n",
        "list_dict=[]\n",
        "for t in tokens_test:\n",
        "  res = {}\n",
        "  for element in t:\n",
        "    res[element]=element.replace(\" \",\"_\")\n",
        "  list_dict.append(res)"
      ],
      "metadata": {
        "id": "rM_CtUonTZnv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "setence_token=[]\n",
        "i=0\n",
        "for texto in  df_test['name'].values:\n",
        "  x=0\n",
        "  palabras = texto.split()\n",
        "  sentcen_token=''\n",
        "  palabras_faltante=[]\n",
        "  for palabra in palabras:\n",
        "    try:\n",
        "     \n",
        "     sentcen_token=sentcen_token+ ' ' +list_dict[i][palabra]\n",
        "    except: \n",
        "      i=i\n",
        "    try:\n",
        "     sentcen_token=sentcen_token+ ' ' + list_dict[i][palabra+ ' '+palabras[x+1]]\n",
        "    except: \n",
        "      i=i\n",
        "    x=x+1\n",
        "  i=i+1\n",
        "  setence_token.append(sentcen_token)"
      ],
      "metadata": {
        "id": "o6dUvo_5Ur7Y"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['sentence_token']=setence_token"
      ],
      "metadata": {
        "id": "8dfZ5tVGU3eo"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del(x_count)"
      ],
      "metadata": {
        "id": "AMSItHALKnps"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del(df_test['name'])"
      ],
      "metadata": {
        "id": "qGnjhuOsK3W2"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del(setence_token)"
      ],
      "metadata": {
        "id": "mdWwY4Z2LbnI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "1xJtYhShKV85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42154229-6889-4a22-cfe8-79fb54bc94cd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2337"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df_test['name_array'] = df_test['sentence_token'].parallel_apply(lambda x: nltk.word_tokenize(x))\n",
        "df_test['name_array'] \n"
      ],
      "metadata": {
        "id": "tXK5bkdPASxb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "c1e2adcab36d4c5ea83d28bf8638a01c",
            "f62a324250ed4c97b35a172d17f77595",
            "62ffe3215f084c2583e912e660a197af",
            "a676942b510d40e0afca35d2fcdc1a47",
            "0e80cd18f9e14108bc72315090e8f7da",
            "04ac6cb8bfc1485c93708d1ad577d170",
            "72339df8c3a9410b8b14513d2f07a991",
            "bf5ac7357498478e9444efa8c1972efe",
            "cc9da89ce5f14c699ded6f85540bbc4f",
            "b305dfeaf1a2450aab4dc6c23729bdd5"
          ]
        },
        "outputId": "a4451fc4-eee5-473b-d934-36d48cddaca6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=118332), Label(value='0 / 118332')…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1e2adcab36d4c5ea83d28bf8638a01c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         [archive, graphic, print, hoodie, gender, men,...\n",
              "1          [feather, hem, shirt, gender, women, highlights]\n",
              "2         [logo, print, joggers, gender, men, highlights...\n",
              "3         [logo, embroidered, mock, neck, top, gender, w...\n",
              "4         [zigzag, embossed, logo, slides, gender, women...\n",
              "                                ...                        \n",
              "118327    [detachable, sleeves, zip, up, jacket, gender,...\n",
              "118328    [line, mini, skirt, gender, women, highlights,...\n",
              "118329    [slogan, print, oversized, vest, gender, women...\n",
              "118330    [reversible, metallic, trim, zipped, jacket, g...\n",
              "118331    [appliqué, detail, long, sleeve, top, gender, ...\n",
              "Name: name_array, Length: 118332, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.compat import np_version_under1p18\n",
        "embeddings=[]\n",
        "for w  in df_test['name_array'].values:\n",
        "  word_embedding=[]\n",
        "  for element in w:\n",
        "    try:\n",
        "      word_embedding.append(model.wv.get_vector(element))\n",
        "    except:\n",
        "      1==1\n",
        "\n",
        "  a=np.array(word_embedding)\n",
        "  avg=np.average(a, axis=0)\n",
        "  embeddings.append(avg)"
      ],
      "metadata": {
        "id": "wXRnJEv-OSXX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr_test = np.array(embeddings)\n",
        "arr_test=np.asfarray(arr_test,float)\n",
        "y_predicted=modelo.predict(arr_test)"
      ],
      "metadata": {
        "id": "vC9AxUBLkqK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "527f384b-c0e1-4ab1-b165-381e67f583f9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3698/3698 [==============================] - 6s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "test_predictions = np.argmax(y_predicted, axis=-1)\n",
        "y_real_test = encoder.fit_transform(df_test.branch)\n",
        "from sklearn.metrics import accuracy_score\n",
        "real=np.argmax(y_real_test, axis=-1)\n",
        "acc=accuracy_score(real,test_predictions )\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "KYPazqMGQ33Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "409989d9-3d41-4b3f-a0a1-74999ea93cf5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8070682486563229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kr9pJI3nMsfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report as cr\n",
        "\n",
        "metrics=(cr(real,test_predictions))\n",
        "print(metrics)"
      ],
      "metadata": {
        "id": "vPh6QMbpvphE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df782f5-c566-4040-f77d-b79c434b62a8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.85      0.90       180\n",
            "           1       0.55      0.71      0.62        45\n",
            "           2       0.88      0.94      0.91       278\n",
            "           3       0.54      0.32      0.40        41\n",
            "           4       0.97      0.98      0.97      2057\n",
            "           5       0.99      0.96      0.97       203\n",
            "           6       0.88      0.86      0.87        35\n",
            "           7       0.84      0.46      0.59        35\n",
            "           8       0.71      0.21      0.33        47\n",
            "           9       0.00      0.00      0.00        37\n",
            "          10       0.38      0.07      0.11        74\n",
            "          11       0.33      0.05      0.09        37\n",
            "          12       0.60      0.32      0.42        77\n",
            "          13       0.32      0.11      0.17        62\n",
            "          14       0.00      0.00      0.00        50\n",
            "          15       0.57      0.06      0.11        64\n",
            "          16       0.67      0.25      0.36        56\n",
            "          17       0.80      0.16      0.27        75\n",
            "          18       0.77      0.86      0.82       131\n",
            "          19       0.83      0.25      0.38       163\n",
            "          20       0.00      0.00      0.00        37\n",
            "          21       0.90      0.45      0.60        58\n",
            "          22       0.70      0.24      0.36        87\n",
            "          23       0.97      0.95      0.96       861\n",
            "          24       0.76      0.54      0.63        41\n",
            "          25       0.93      0.88      0.90       410\n",
            "          26       0.71      0.88      0.78       310\n",
            "          27       0.88      0.88      0.88      1064\n",
            "          28       0.88      0.31      0.45        72\n",
            "          29       0.80      0.59      0.68       125\n",
            "          30       0.71      0.76      0.73       306\n",
            "          31       0.57      0.52      0.55       640\n",
            "          32       0.80      0.84      0.82      2282\n",
            "          33       0.88      0.76      0.82      2981\n",
            "          34       0.86      0.94      0.90      4473\n",
            "          35       0.96      0.78      0.86       392\n",
            "          36       0.80      0.53      0.64       131\n",
            "          37       0.40      0.13      0.20        45\n",
            "          38       0.25      0.02      0.03        54\n",
            "          39       0.95      0.87      0.91       166\n",
            "          40       0.94      0.73      0.82        44\n",
            "          41       1.00      0.72      0.84        58\n",
            "          42       0.42      0.55      0.48        74\n",
            "          43       0.89      0.65      0.75       347\n",
            "          44       0.94      0.77      0.85       150\n",
            "          45       0.52      0.57      0.55       105\n",
            "          46       0.44      0.21      0.29        56\n",
            "          47       0.49      0.17      0.25       234\n",
            "          48       0.57      0.71      0.63       171\n",
            "          49       0.50      0.70      0.58       216\n",
            "          50       0.70      0.58      0.64       148\n",
            "          51       0.52      0.38      0.44        61\n",
            "          52       0.70      0.78      0.74      1340\n",
            "          53       0.74      0.75      0.75       406\n",
            "          54       0.79      0.75      0.77        96\n",
            "          55       0.59      0.50      0.54        92\n",
            "          56       0.82      0.52      0.64        63\n",
            "          57       0.72      0.70      0.71       424\n",
            "          58       0.28      0.17      0.21       135\n",
            "          59       0.24      0.11      0.15        53\n",
            "          60       0.55      0.84      0.67       194\n",
            "          61       0.80      0.33      0.47        36\n",
            "          62       0.81      0.85      0.83       753\n",
            "          63       0.78      0.89      0.83       692\n",
            "          64       0.84      0.82      0.83       548\n",
            "          65       0.77      0.74      0.76       618\n",
            "          66       0.73      0.65      0.69       136\n",
            "          67       0.80      0.80      0.80       275\n",
            "          68       0.00      0.00      0.00        42\n",
            "          69       0.56      0.47      0.51      1946\n",
            "          70       0.78      0.87      0.83      6499\n",
            "          71       0.82      0.35      0.49       861\n",
            "          72       0.00      0.00      0.00        58\n",
            "          73       0.68      0.29      0.41       145\n",
            "          74       0.93      0.94      0.94      3259\n",
            "          75       0.75      0.71      0.73      1095\n",
            "          76       0.36      0.32      0.34        77\n",
            "          77       0.47      0.58      0.52       278\n",
            "          78       0.88      0.90      0.89       629\n",
            "          79       0.56      0.46      0.51        89\n",
            "          80       0.32      0.42      0.36       368\n",
            "          81       0.61      0.66      0.63       437\n",
            "          82       0.66      0.69      0.68       518\n",
            "          83       0.50      0.45      0.47       594\n",
            "          84       0.32      0.11      0.16       112\n",
            "          85       0.00      0.00      0.00        35\n",
            "          86       0.28      0.27      0.27       263\n",
            "          87       0.68      0.85      0.76       732\n",
            "          88       0.73      0.83      0.78       717\n",
            "          89       0.72      0.72      0.72       555\n",
            "          90       0.61      0.49      0.55       344\n",
            "          91       0.00      0.00      0.00        37\n",
            "          92       0.56      0.71      0.63       108\n",
            "          93       0.77      0.75      0.76       260\n",
            "          94       0.89      0.84      0.86       427\n",
            "          95       0.75      0.56      0.64       136\n",
            "          96       0.91      0.94      0.93      1704\n",
            "          97       0.89      0.93      0.91      3756\n",
            "          98       0.52      0.67      0.58       488\n",
            "          99       0.44      0.79      0.57       158\n",
            "         100       0.69      0.76      0.72      1830\n",
            "         101       0.40      0.46      0.43       172\n",
            "         102       0.96      0.98      0.97      1991\n",
            "         103       0.96      0.94      0.95      4381\n",
            "         104       0.55      0.81      0.65       620\n",
            "         105       0.86      0.47      0.61       188\n",
            "         106       0.85      0.53      0.65       167\n",
            "         107       0.00      0.00      0.00       100\n",
            "         108       0.70      0.83      0.76       109\n",
            "         109       0.80      0.60      0.69        55\n",
            "         110       0.65      0.18      0.28       373\n",
            "         111       0.62      0.33      0.43        69\n",
            "         112       0.00      0.00      0.00       104\n",
            "         113       0.60      0.91      0.72      1190\n",
            "         114       0.57      0.25      0.34       204\n",
            "         115       0.80      0.78      0.79       749\n",
            "         116       0.38      0.65      0.48       676\n",
            "         117       0.57      0.67      0.62       344\n",
            "         118       0.46      0.28      0.35       320\n",
            "         119       0.45      0.14      0.22       235\n",
            "         120       0.47      0.45      0.46       869\n",
            "         121       0.76      0.60      0.67       257\n",
            "         122       0.70      0.67      0.69       414\n",
            "         123       0.41      0.13      0.19       321\n",
            "         124       0.72      0.68      0.70        38\n",
            "         125       0.97      0.94      0.96       421\n",
            "         126       0.93      0.92      0.92       569\n",
            "         127       0.94      0.96      0.95      2635\n",
            "         128       0.92      0.90      0.91      2994\n",
            "         129       0.00      0.00      0.00        42\n",
            "         130       0.90      0.88      0.89      2120\n",
            "         131       0.00      0.00      0.00        67\n",
            "         132       0.95      0.96      0.96      7645\n",
            "         133       0.84      0.78      0.81       209\n",
            "         134       0.82      0.81      0.82      3080\n",
            "         135       0.00      0.00      0.00        65\n",
            "         136       0.82      0.93      0.87      1126\n",
            "         137       0.00      0.00      0.00        56\n",
            "         138       0.79      0.61      0.68       188\n",
            "         139       0.91      0.91      0.91      2895\n",
            "         140       0.86      0.86      0.86      1247\n",
            "         141       0.86      0.89      0.87      5015\n",
            "         142       0.52      0.28      0.37        81\n",
            "         143       0.74      0.75      0.75      1862\n",
            "         144       0.85      0.79      0.82       529\n",
            "         145       0.74      0.76      0.75      1473\n",
            "         146       0.72      0.62      0.66        78\n",
            "         147       0.52      0.74      0.61       634\n",
            "         148       0.48      0.51      0.49       936\n",
            "         149       0.66      0.92      0.77       372\n",
            "         150       0.68      0.16      0.26       128\n",
            "         151       0.00      0.00      0.00        47\n",
            "         152       0.47      0.58      0.52       403\n",
            "         153       0.79      0.74      0.77      1633\n",
            "         154       0.54      0.51      0.52       263\n",
            "         155       0.69      0.44      0.54       281\n",
            "         156       0.77      0.44      0.56       842\n",
            "         157       0.72      0.69      0.70       879\n",
            "         158       0.68      0.73      0.71       557\n",
            "         159       0.84      0.92      0.88      2469\n",
            "         160       0.65      0.68      0.66       164\n",
            "         161       0.68      0.45      0.54        38\n",
            "         162       0.85      0.62      0.72        37\n",
            "         163       0.70      0.62      0.66        34\n",
            "         164       0.71      0.45      0.56        33\n",
            "         165       0.94      0.70      0.80        43\n",
            "         166       0.90      0.98      0.94       654\n",
            "         167       0.93      0.78      0.84        49\n",
            "         168       0.85      0.98      0.91       511\n",
            "         169       0.95      0.92      0.93       643\n",
            "         170       0.94      0.92      0.93       298\n",
            "         171       0.87      0.91      0.89        45\n",
            "         172       0.25      0.09      0.14        86\n",
            "         173       0.57      0.59      0.58        34\n",
            "         174       0.00      0.00      0.00        42\n",
            "         175       0.89      0.76      0.82        88\n",
            "         176       0.98      0.92      0.95       184\n",
            "         177       0.91      0.88      0.90       212\n",
            "         178       0.87      0.99      0.93        88\n",
            "         179       0.93      0.93      0.93       307\n",
            "         180       0.99      0.86      0.92        86\n",
            "         181       0.96      0.96      0.96       512\n",
            "         182       0.89      0.79      0.84        39\n",
            "         183       0.59      0.71      0.64        34\n",
            "         184       0.63      0.67      0.65        46\n",
            "         185       0.90      0.83      0.86       118\n",
            "         186       0.68      0.81      0.74       156\n",
            "         187       0.87      0.87      0.87       202\n",
            "         188       0.92      0.87      0.89       484\n",
            "         189       0.86      0.35      0.50        34\n",
            "         190       0.63      0.37      0.47        65\n",
            "         191       0.83      0.94      0.88       411\n",
            "         192       0.89      0.94      0.91       351\n",
            "         193       0.96      0.89      0.92        53\n",
            "\n",
            "    accuracy                           0.81    118332\n",
            "   macro avg       0.66      0.59      0.61    118332\n",
            "weighted avg       0.80      0.81      0.80    118332\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediccion=encoder.inverse_transform(modelo.predict(arr_test))\n",
        "resultados=pd.DataFrame(df_test.branch)\n",
        "resultados['prediction']=list(prediccion)\n",
        "resultados.to_csv('rn-word2vect_avg-real-target.csv')"
      ],
      "metadata": {
        "id": "0oOynelvo8Sk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3a0ca68-944d-48ed-d5bd-40f3663064b9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3698/3698 [==============================] - 8s 2ms/step\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "432ff387442b491682c839590c9cad48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_772d1b4e03f9471d8a91a9767ca5c4f4"
            ],
            "layout": "IPY_MODEL_7d7f9d50be38458ca163aca93d322b7e"
          }
        },
        "772d1b4e03f9471d8a91a9767ca5c4f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f4447018d954f1e87ab80ede9886ac1",
              "IPY_MODEL_96aa2c29f73a456e958868423b986c9f"
            ],
            "layout": "IPY_MODEL_cfb413ee104e4d789ce7d88efbf05a31"
          }
        },
        "7d7f9d50be38458ca163aca93d322b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f4447018d954f1e87ab80ede9886ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100.00%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e9c1e3f1b30436ab0d63b2793341bcc",
            "max": 276107,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f5a6a55bc5b49eeb6369c6705ea1c4a",
            "value": 276107
          }
        },
        "96aa2c29f73a456e958868423b986c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a052b5e9f6b340868539049df2ab6bfc",
            "placeholder": "​",
            "style": "IPY_MODEL_fe726dc1bf9848d180deb2e9414da6ab",
            "value": "276107 / 276107"
          }
        },
        "cfb413ee104e4d789ce7d88efbf05a31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e9c1e3f1b30436ab0d63b2793341bcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f5a6a55bc5b49eeb6369c6705ea1c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a052b5e9f6b340868539049df2ab6bfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe726dc1bf9848d180deb2e9414da6ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1e2adcab36d4c5ea83d28bf8638a01c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f62a324250ed4c97b35a172d17f77595"
            ],
            "layout": "IPY_MODEL_62ffe3215f084c2583e912e660a197af"
          }
        },
        "f62a324250ed4c97b35a172d17f77595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a676942b510d40e0afca35d2fcdc1a47",
              "IPY_MODEL_0e80cd18f9e14108bc72315090e8f7da"
            ],
            "layout": "IPY_MODEL_04ac6cb8bfc1485c93708d1ad577d170"
          }
        },
        "62ffe3215f084c2583e912e660a197af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a676942b510d40e0afca35d2fcdc1a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100.00%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72339df8c3a9410b8b14513d2f07a991",
            "max": 118332,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf5ac7357498478e9444efa8c1972efe",
            "value": 118332
          }
        },
        "0e80cd18f9e14108bc72315090e8f7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc9da89ce5f14c699ded6f85540bbc4f",
            "placeholder": "​",
            "style": "IPY_MODEL_b305dfeaf1a2450aab4dc6c23729bdd5",
            "value": "118332 / 118332"
          }
        },
        "04ac6cb8bfc1485c93708d1ad577d170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72339df8c3a9410b8b14513d2f07a991": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf5ac7357498478e9444efa8c1972efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc9da89ce5f14c699ded6f85540bbc4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b305dfeaf1a2450aab4dc6c23729bdd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}